{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/cyberfury/Kaggle/blob/main/Titanic.ipynb",
      "authorship_tag": "ABX9TyMmC1T1egXhzTPgs/d/RJGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyberfury/Kaggle/blob/main/Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_path=\"/content/drive/MyDrive/KaggleDownload/titanic/test.csv\"\n",
        "train_path=\"/content/drive/MyDrive/KaggleDownload/titanic/train.csv\"\n",
        "\n",
        "test_df=pd.read_csv(test_path)\n",
        "train_df=pd.read_csv(train_path)\n"
      ],
      "metadata": {
        "id": "0l2moWZ2XpQS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piFM6DUdXyOH",
        "outputId": "35c188cf-ca21-405f-bd99-c0c488f91076"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 문제 \n",
        "# 로지스틱 / xg부스트 / 앙상블 사용해볼것\n",
        "# 각 데이터를 수치형으로 변환\n",
        "# 상관성이있는 데이터들을 추출\n",
        "# 학습 후 예측"
      ],
      "metadata": {
        "id": "RbuPoV1-Xy0T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추후 test 데이터도 전처리 해줘야 하기에, 카피 데이터프레임을 생성해둔다\n",
        "df=train_df.copy() "
      ],
      "metadata": {
        "id": "RnnregmYJl4z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cabin, Ticket, Name 값은 100개이상으로 숫자변환 대상에서 우선 제외\n",
        "# Pclass, SibSp, Parch, Fare 이미 숫자로 나타나 있어 굳이 고칠필요없음\n",
        "# Age는 상관성이 높은 Pclass,SibSp 을 학습시켜 대입해볼것 - 상관성 0.3이상\n",
        "\n",
        "###################################################################\n",
        "# Embarked, Sex는 아래처럼 전처리함\n",
        "\n",
        "# 전처리1. 성별을 숫자로 변환\n",
        "# 성별은 male, female 바이너리 값임\n",
        "df['Sex']=df['Sex'].apply(lambda x: 0 if x=='male' else 1)\n",
        "\n",
        "# 전처리2. Embarked 을 원핫인코딩함. \n",
        "# Embarked 는 S C Q 문자로 나타남\n",
        "df_merged=pd.concat([df,pd.get_dummies(df['Embarked'])],axis=1)\n",
        "###################################################################\n",
        "\n",
        "# 최종 Feature\n",
        "# [['Sex','Embarked','SibSp','Pclass','Fare','Parch']]"
      ],
      "metadata": {
        "id": "RIrlAzLza3_O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Age의 빈값을, Pclass, SibSP 값으로 예측값을 넣어보자\n",
        "\n",
        "import sklearn \n",
        "from sklearn import *\n",
        "\n",
        "# 모델분류\n",
        "# sklearn.model_selection.train_test_split\n",
        "# 학습모델 - 랜덤포레스트\n",
        "# sklearn.ensemble.RandomForestClassifier"
      ],
      "metadata": {
        "id": "HdOSVI83McG9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_age_model=df_merged[df_merged['Sex'].notnull()][['PassengerId','Pclass','SibSp','Age']].copy()"
      ],
      "metadata": {
        "id": "hg-wqx89NL2v"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df_age_model[['Pclass','SibSp']], df_age_model['Age'], test_size=0.33, random_state=714)"
      ],
      "metadata": {
        "id": "djF1Svu9NIni"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a90Ai-lCNIgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZhgHYh3ENIcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GlZJb-vNNIY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mahqYMPrNIJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sklearn.ensemble.RandomForestRegressor)"
      ],
      "metadata": {
        "id": "kJEfaFPQMcA7",
        "outputId": "27038a27-70c5-4b24-edeb-96f6430e73a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
            "\n",
            "class RandomForestRegressor(ForestRegressor)\n",
            " |  RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
            " |  \n",
            " |  A random forest regressor.\n",
            " |  \n",
            " |  A random forest is a meta estimator that fits a number of classifying\n",
            " |  decision trees on various sub-samples of the dataset and uses averaging\n",
            " |  to improve the predictive accuracy and control over-fitting.\n",
            " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
            " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
            " |  each tree.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <forest>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_estimators : int, default=100\n",
            " |      The number of trees in the forest.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |         The default value of ``n_estimators`` changed from 10 to 100\n",
            " |         in 0.22.\n",
            " |  \n",
            " |  criterion : {\"squared_error\", \"absolute_error\", \"poisson\"},             default=\"squared_error\"\n",
            " |      The function to measure the quality of a split. Supported criteria\n",
            " |      are \"squared_error\" for the mean squared error, which is equal to\n",
            " |      variance reduction as feature selection criterion, \"absolute_error\"\n",
            " |      for the mean absolute error, and \"poisson\" which uses reduction in\n",
            " |      Poisson deviance to find splits.\n",
            " |      Training using \"absolute_error\" is significantly slower\n",
            " |      than when using \"squared_error\".\n",
            " |  \n",
            " |      .. versionadded:: 0.18\n",
            " |         Mean Absolute Error (MAE) criterion.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |         Poisson criterion.\n",
            " |  \n",
            " |      .. deprecated:: 1.0\n",
            " |          Criterion \"mse\" was deprecated in v1.0 and will be removed in\n",
            " |          version 1.2. Use `criterion=\"squared_error\"` which is equivalent.\n",
            " |  \n",
            " |      .. deprecated:: 1.0\n",
            " |          Criterion \"mae\" was deprecated in v1.0 and will be removed in\n",
            " |          version 1.2. Use `criterion=\"absolute_error\"` which is equivalent.\n",
            " |  \n",
            " |  max_depth : int, default=None\n",
            " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
            " |      all leaves are pure or until all leaves contain less than\n",
            " |      min_samples_split samples.\n",
            " |  \n",
            " |  min_samples_split : int or float, default=2\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int or float, default=1\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, default=0.0\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |      - If int, then consider `max_features` features at each split.\n",
            " |      - If float, then `max_features` is a fraction and\n",
            " |        `round(max_features * n_features)` features are considered at each\n",
            " |        split.\n",
            " |      - If \"auto\", then `max_features=n_features`.\n",
            " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |      - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  max_leaf_nodes : int, default=None\n",
            " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  min_impurity_decrease : float, default=0.0\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  bootstrap : bool, default=True\n",
            " |      Whether bootstrap samples are used when building trees. If False, the\n",
            " |      whole dataset is used to build each tree.\n",
            " |  \n",
            " |  oob_score : bool, default=False\n",
            " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
            " |      Only available if bootstrap=True.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
            " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
            " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
            " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
            " |      <n_jobs>` for more details.\n",
            " |  \n",
            " |  random_state : int, RandomState instance or None, default=None\n",
            " |      Controls both the randomness of the bootstrapping of the samples used\n",
            " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
            " |      features to consider when looking for the best split at each node\n",
            " |      (if ``max_features < n_features``).\n",
            " |      See :term:`Glossary <random_state>` for details.\n",
            " |  \n",
            " |  verbose : int, default=0\n",
            " |      Controls the verbosity when fitting and predicting.\n",
            " |  \n",
            " |  warm_start : bool, default=False\n",
            " |      When set to ``True``, reuse the solution of the previous call to fit\n",
            " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
            " |      new forest. See :term:`the Glossary <warm_start>`.\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, default=0.0\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  max_samples : int or float, default=None\n",
            " |      If bootstrap is True, the number of samples to draw from X\n",
            " |      to train each base estimator.\n",
            " |  \n",
            " |      - If None (default), then draw `X.shape[0]` samples.\n",
            " |      - If int, then draw `max_samples` samples.\n",
            " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
            " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  base_estimator_ : DecisionTreeRegressor\n",
            " |      The child estimator template used to create the collection of fitted\n",
            " |      sub-estimators.\n",
            " |  \n",
            " |  estimators_ : list of DecisionTreeRegressor\n",
            " |      The collection of fitted sub-estimators.\n",
            " |  \n",
            " |  feature_importances_ : ndarray of shape (n_features,)\n",
            " |      The impurity-based feature importances.\n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance.\n",
            " |  \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |  \n",
            " |  n_features_ : int\n",
            " |      The number of features when ``fit`` is performed.\n",
            " |  \n",
            " |      .. deprecated:: 1.0\n",
            " |          Attribute `n_features_` was deprecated in version 1.0 and will be\n",
            " |          removed in 1.2. Use `n_features_in_` instead.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_outputs_ : int\n",
            " |      The number of outputs when ``fit`` is performed.\n",
            " |  \n",
            " |  oob_score_ : float\n",
            " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
            " |      This attribute exists only when ``oob_score`` is True.\n",
            " |  \n",
            " |  oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |      Prediction computed with out-of-bag estimate on the training set.\n",
            " |      This attribute exists only when ``oob_score`` is True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
            " |  sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
            " |      tree regressors.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The default values for the parameters controlling the size of the trees\n",
            " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
            " |  unpruned trees which can potentially be very large on some data sets. To\n",
            " |  reduce memory consumption, the complexity and size of the trees should be\n",
            " |  controlled by setting those parameter values.\n",
            " |  \n",
            " |  The features are always randomly permuted at each split. Therefore,\n",
            " |  the best found split may vary, even with the same training data,\n",
            " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
            " |  of the criterion is identical for several splits enumerated during the\n",
            " |  search of the best split. To obtain a deterministic behaviour during\n",
            " |  fitting, ``random_state`` has to be fixed.\n",
            " |  \n",
            " |  The default value ``max_features=\"auto\"`` uses ``n_features``\n",
            " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
            " |  [1], whereas the former was more recently justified empirically in [2].\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
            " |  \n",
            " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
            " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
            " |  >>> from sklearn.datasets import make_regression\n",
            " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
            " |  ...                        random_state=0, shuffle=False)\n",
            " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
            " |  >>> regr.fit(X, y)\n",
            " |  RandomForestRegressor(...)\n",
            " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
            " |  [-8.32987858]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      RandomForestRegressor\n",
            " |      ForestRegressor\n",
            " |      sklearn.base.RegressorMixin\n",
            " |      BaseForest\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.ensemble._base.BaseEnsemble\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from ForestRegressor:\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict regression target for X.\n",
            " |      \n",
            " |      The predicted regression target of an input sample is computed as the\n",
            " |      mean predicted regression targets of the trees in the forest.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The predicted values.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.RegressorMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the coefficient of determination of the prediction.\n",
            " |      \n",
            " |      The coefficient of determination :math:`R^2` is defined as\n",
            " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
            " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
            " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
            " |      The best possible score is 1.0 and it can be negative (because the\n",
            " |      model can be arbitrarily worse). A constant model that always predicts\n",
            " |      the expected value of `y`, disregarding the input features, would get\n",
            " |      a :math:`R^2` score of 0.0.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples. For some estimators this may be a precomputed\n",
            " |          kernel matrix or a list of generic objects instead with shape\n",
            " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
            " |          is the number of samples used in the fitting for the estimator.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True values for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
            " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
            " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
            " |      This influences the ``score`` method of all the multioutput\n",
            " |      regressors (except for\n",
            " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseForest:\n",
            " |  \n",
            " |  apply(self, X)\n",
            " |      Apply trees in the forest to X, return leaf indices.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
            " |          For each datapoint x in X and for each tree in the forest,\n",
            " |          return the index of the leaf x ends up in.\n",
            " |  \n",
            " |  decision_path(self, X)\n",
            " |      Return the decision path in the forest.\n",
            " |      \n",
            " |      .. versionadded:: 0.18\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
            " |          Return a node indicator matrix where non zero elements indicates\n",
            " |          that the samples goes through the nodes. The matrix is of CSR\n",
            " |          format.\n",
            " |      \n",
            " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
            " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
            " |          gives the indicator value for the i-th estimator.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None)\n",
            " |      Build a forest of trees from the training set (X, y).\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
            " |          The training input samples. Internally, its dtype will be converted\n",
            " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
            " |          converted into a sparse ``csc_matrix``.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          The target values (class labels in classification, real numbers in\n",
            " |          regression).\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. In the case of\n",
            " |          classification, splits are also ignored if they would result in any\n",
            " |          single class carrying a negative weight in either child node.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Fitted estimator.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from BaseForest:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      The impurity-based feature importances.\n",
            " |      \n",
            " |      The higher, the more important the feature.\n",
            " |      The importance of a feature is computed as the (normalized)\n",
            " |      total reduction of the criterion brought by that feature.  It is also\n",
            " |      known as the Gini importance.\n",
            " |      \n",
            " |      Warning: impurity-based feature importances can be misleading for\n",
            " |      high cardinality features (many unique values). See\n",
            " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : ndarray of shape (n_features,)\n",
            " |          The values of this array sum to 1, unless all trees are single node\n",
            " |          trees consisting of only the root node, in which case it will be an\n",
            " |          array of zeros.\n",
            " |  \n",
            " |  n_features_\n",
            " |      DEPRECATED: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
            " |      \n",
            " |      Number of features when fitting the estimator.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
            " |  \n",
            " |  __getitem__(self, index)\n",
            " |      Return the index'th estimator in the ensemble.\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |      Return iterator over estimators in the ensemble.\n",
            " |  \n",
            " |  __len__(self)\n",
            " |      Return the number of estimators in the ensemble.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
            " |  \n",
            " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GewZluszMb7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wybli2H_Mb2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K-wu6q_NMbFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QlmnQWxAfQAW",
        "outputId": "18eeed79-1ca4-4609-a9b1-7ca178899be4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-290a620a-769c-4ca2-8a7f-dfb579b44583\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-290a620a-769c-4ca2-8a7f-dfb579b44583')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-290a620a-769c-4ca2-8a7f-dfb579b44583 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-290a620a-769c-4ca2-8a7f-dfb579b44583');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...  C  Q  S\n",
              "0              1         0       3  ...  0  0  1\n",
              "1              2         1       1  ...  1  0  0\n",
              "2              3         1       3  ...  0  0  1\n",
              "3              4         1       1  ...  0  0  1\n",
              "4              5         0       3  ...  0  0  1\n",
              "..           ...       ...     ...  ... .. .. ..\n",
              "886          887         0       2  ...  0  0  1\n",
              "887          888         1       1  ...  0  0  1\n",
              "888          889         0       3  ...  0  0  1\n",
              "889          890         1       1  ...  1  0  0\n",
              "890          891         0       3  ...  0  1  0\n",
              "\n",
              "[891 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상관성 현황\n",
        "df_merged.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "J-VdTgx9JaN2",
        "outputId": "497a39ee-0fee-43d4-b27f-8a3fb97afe10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c5257810-b6b1-46ca-8db3-e8481cb36f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005007</td>\n",
              "      <td>-0.035144</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.012658</td>\n",
              "      <td>-0.001205</td>\n",
              "      <td>-0.033606</td>\n",
              "      <td>0.022148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <td>-0.005007</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.257307</td>\n",
              "      <td>0.168240</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>-0.155660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>-0.035144</td>\n",
              "      <td>-0.338481</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>-0.549500</td>\n",
              "      <td>-0.243292</td>\n",
              "      <td>0.221009</td>\n",
              "      <td>0.081720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.036847</td>\n",
              "      <td>-0.077221</td>\n",
              "      <td>-0.369226</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.096067</td>\n",
              "      <td>0.036261</td>\n",
              "      <td>-0.022405</td>\n",
              "      <td>-0.032523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>-0.057527</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>0.083081</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.308247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>0.159651</td>\n",
              "      <td>-0.059528</td>\n",
              "      <td>-0.026354</td>\n",
              "      <td>0.070941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>-0.001652</td>\n",
              "      <td>0.081629</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.189119</td>\n",
              "      <td>0.414838</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.216225</td>\n",
              "      <td>-0.011069</td>\n",
              "      <td>-0.081228</td>\n",
              "      <td>0.063036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.012658</td>\n",
              "      <td>0.257307</td>\n",
              "      <td>-0.549500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.096067</td>\n",
              "      <td>0.159651</td>\n",
              "      <td>0.216225</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.269335</td>\n",
              "      <td>-0.117216</td>\n",
              "      <td>-0.166603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>-0.001205</td>\n",
              "      <td>0.168240</td>\n",
              "      <td>-0.243292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.036261</td>\n",
              "      <td>-0.059528</td>\n",
              "      <td>-0.011069</td>\n",
              "      <td>0.269335</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.148258</td>\n",
              "      <td>-0.778359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q</th>\n",
              "      <td>-0.033606</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.221009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.022405</td>\n",
              "      <td>-0.026354</td>\n",
              "      <td>-0.081228</td>\n",
              "      <td>-0.117216</td>\n",
              "      <td>-0.148258</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.496624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S</th>\n",
              "      <td>0.022148</td>\n",
              "      <td>-0.155660</td>\n",
              "      <td>0.081720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.032523</td>\n",
              "      <td>0.070941</td>\n",
              "      <td>0.063036</td>\n",
              "      <td>-0.166603</td>\n",
              "      <td>-0.778359</td>\n",
              "      <td>-0.496624</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5257810-b6b1-46ca-8db3-e8481cb36f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5257810-b6b1-46ca-8db3-e8481cb36f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5257810-b6b1-46ca-8db3-e8481cb36f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             PassengerId  Survived    Pclass  ...         C         Q         S\n",
              "PassengerId     1.000000 -0.005007 -0.035144  ... -0.001205 -0.033606  0.022148\n",
              "Survived       -0.005007  1.000000 -0.338481  ...  0.168240  0.003650 -0.155660\n",
              "Pclass         -0.035144 -0.338481  1.000000  ... -0.243292  0.221009  0.081720\n",
              "Sex                  NaN       NaN       NaN  ...       NaN       NaN       NaN\n",
              "Age             0.036847 -0.077221 -0.369226  ...  0.036261 -0.022405 -0.032523\n",
              "SibSp          -0.057527 -0.035322  0.083081  ... -0.059528 -0.026354  0.070941\n",
              "Parch          -0.001652  0.081629  0.018443  ... -0.011069 -0.081228  0.063036\n",
              "Fare            0.012658  0.257307 -0.549500  ...  0.269335 -0.117216 -0.166603\n",
              "C              -0.001205  0.168240 -0.243292  ...  1.000000 -0.148258 -0.778359\n",
              "Q              -0.033606  0.003650  0.221009  ... -0.148258  1.000000 -0.496624\n",
              "S               0.022148 -0.155660  0.081720  ... -0.778359 -0.496624  1.000000\n",
              "\n",
              "[11 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}